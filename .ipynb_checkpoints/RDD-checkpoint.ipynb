{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e9cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext, SparkConf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c94035",
   "metadata": {},
   "source": [
    "# 创建RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0c925",
   "metadata": {},
   "source": [
    "## 1. 并行化创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8a25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('test').setMaster('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437a276e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x1309282fe20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.default.parallesim', '50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fd3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbd67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafb41bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认根据CPU 分区\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db05d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb8f97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7342b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8985b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 发到driver  \n",
    "# 分布式 转 本地集合\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e9d2a",
   "metadata": {},
   "source": [
    "## 2. 读文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a02607",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rdd1 = sc.textFile('word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3968ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a3e187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadoop hadoop spark', 'hadoop hadoop spark', 'hadoop hadoop spark flink']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf49ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# 加最小分区数 spark 有自己的测速测试 给太大不理会 \n",
    "file_rdd2 = sc.textFile('word.txt', 3)\n",
    "print(file_rdd2.getNumPartitions())\n",
    "file_rdd3 = sc.textFile('word.txt', 100)\n",
    "print(file_rdd3.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3b029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0b1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e346d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57802cd5",
   "metadata": {},
   "source": [
    "# Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2a1bc",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdd42d",
   "metadata": {},
   "source": [
    "## 1. map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08ec0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(data): return data*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7593184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113d0462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda data: data*10).collect( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d69da2",
   "metadata": {},
   "source": [
    "## 2.flatMap  => 先map 后解除嵌套"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef8cef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word.txt MapPartitionsRDD[3] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74acb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = file_rdd1.map(lambda line: line.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa6776c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hadoop', 'hadoop', 'spark'],\n",
       " ['hadoop', 'hadoop', 'spark'],\n",
       " ['hadoop', 'hadoop', 'spark', 'flink']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e06f6277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'flink']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd1.flatMap(lambda line: line.split(' ')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798de1d",
   "metadata": {},
   "source": [
    "## 3.ReducebyKey  => 针对 Keyvalue rdd =》先分组再聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2afe96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('a', 1), ('a', 1), ('b', 1), ('b', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ecf93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('a', 3)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe2a0d",
   "metadata": {},
   "source": [
    "## 3.mapValue  => 针对 Keyvalue rdd 中的 value =》先分组再聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ce92021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 10), ('a', 10), ('a', 10), ('b', 10), ('b', 10)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x:(x[0], x[1]*10)).collect( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3002b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 10), ('a', 10), ('a', 10), ('b', 10), ('b', 10)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(lambda value:value*10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31175e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501bcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b6a5f8",
   "metadata": {},
   "source": [
    "# eg:Word COunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "446299b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word.txt MapPartitionsRDD[3] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rdd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4b5ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出所有 word\n",
    "word_rdd = file_rdd1.flatMap(lambda line: line.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28417cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'flink']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a9282bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key 是单词 value 是1\n",
    "word_with_one_rdd = word_rdd.map(lambda word: (word,1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2ee0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相加\n",
    "result_rdd = word_with_one_rdd.reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc3e5159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hadoop', 6), ('spark', 3), ('flink', 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe1fee",
   "metadata": {},
   "source": [
    "## 4.groupBy   和sql一样 =》 hash分组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7106f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('a', 1), ('a', 1), ('b', 1), ('b', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11ce0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过函数按照谁来分组 key 或 value =》 f返回谁即可\n",
    "result = rdd.groupBy(lambda t:t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e61ff470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', <pyspark.resultiterable.ResultIterable at 0x1a71d7a1310>),\n",
       " ('a', <pyspark.resultiterable.ResultIterable at 0x1a71d4112b0>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a92b9532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', [('b', 1), ('b', 1)]), ('a', [('a', 1), ('a', 1), ('a', 1)])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.map(lambda t:(t[0], list(t[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3bbc3",
   "metadata": {},
   "source": [
    "## 5.filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aad164bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23a2f9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x : x%2 ==1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd3e2f",
   "metadata": {},
   "source": [
    "## 6. distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5c2e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('a', 1), ('a', 1), ('b', 1), ('b', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bf5ee78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e90f89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1,2,3, 1, 3, 2]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52065037",
   "metadata": {},
   "source": [
    "## 7.Union => 不会和并  可以合并不同的东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8b40be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('a', 1), ('a', 1), ('b', 1), ('b', 1), 1, 2, 3, 1, 3, 2]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.union(   sc.parallelize([1,2,3, 1, 3, 2])    ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce735e6",
   "metadata": {},
   "source": [
    "## 8.Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0757bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([  (1001, '张三'), (1002, '李四')  , (1003, '王五')   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b3f2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize(   [   (1001, '销售部'),  (1002, '科技部')] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c1bd107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, ('张三', '销售部')), (1002, ('李四', '科技部'))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.join(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "431d9417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, ('张三', '销售部')), (1002, ('李四', '科技部')), (1003, ('王五', None))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.leftOuterJoin(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a310c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, ('张三', '销售部')), (1002, ('李四', '科技部'))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.rightOuterJoin(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22685c8",
   "metadata": {},
   "source": [
    "## 9.Intersection => union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "400e55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([('a', 1), ('a', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6c20a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize([('a', 1), ('b', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f2981e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df650cd",
   "metadata": {},
   "source": [
    "## 10. glom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d95dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a224e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[113] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.glom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32d6c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.glom().flatMap( lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00452b1",
   "metadata": {},
   "source": [
    "## 10. groupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a07297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('a', 1), ('a', 1), ('a', 1), ('b', 1), ('b', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f28fde60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', <pyspark.resultiterable.ResultIterable at 0x1a71e9dfe80>),\n",
       " ('a', <pyspark.resultiterable.ResultIterable at 0x1a71e9dff40>)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52d14ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', [1, 1]), ('a', [1, 1, 1])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.groupByKey().map(lambda x:(x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98dd9",
   "metadata": {},
   "source": [
    "## 10. sortBy => 只是分区排序，全局排序就是 numPartitions =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f47cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('x', 1), ('w', 2), ('c', 4), ('g', 123), ('b', 16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06339557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', 1), ('w', 2), ('c', 4), ('b', 16), ('g', 123)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sortBy(lambda x: x[1], ascending=True, numPartitions=1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0384462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 16), ('c', 4), ('g', 123), ('w', 2), ('x', 1)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sortBy(lambda x:x[0], ascending=True, numPartitions=1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5411fe0",
   "metadata": {},
   "source": [
    "## 11. sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d0fe5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([('x', 1), ('w', 2), ('C', 4), ('g', 123), ('B', 16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "453c2803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 16), ('C', 4), ('g', 123), ('w', 2), ('x', 1)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sortByKey(ascending=True, numPartitions=3,     keyfunc=    lambda  key: str(key).lower()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cfaa27",
   "metadata": {},
   "source": [
    "# Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149fbdb",
   "metadata": {},
   "source": [
    "## 1. countByKey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8aad9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "38bf8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.flatMap(lambda x:x.split(' ')).map(lambda x: (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5f67aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'hadoop': 6, 'spark': 3, 'flink': 1})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44acc554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd2.countByKey())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d079ac",
   "metadata": {},
   "source": [
    "## 2.collect => 把各个分区的数据都拉到Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e948a2",
   "metadata": {},
   "source": [
    "## 3.reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e7bc836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ca9a265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5623d",
   "metadata": {},
   "source": [
    "## 4.fold => 带有初始值的reduce\n",
    "分区内有\n",
    "分区间也有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "44e8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c1b78730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a6228614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.fold(10, lambda a, b : a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bad02",
   "metadata": {},
   "source": [
    "## 5. first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2facbebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcedfd",
   "metadata": {},
   "source": [
    "## 6. take 前n个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ae15c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272834e",
   "metadata": {},
   "source": [
    "## 7. top 降序排序的前几个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1ba8282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd= sc.parallelize([123,2123,1233,4,54,6,7,8,9], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6aee6e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 1233, 123]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b2c9c",
   "metadata": {},
   "source": [
    "## 8.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ed4a938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f8c1d",
   "metadata": {},
   "source": [
    "## 9.takeSample 抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4594eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 54, 8, 7, 123, 9, 8, 9, 123, 1233, 4, 8, 7, 1233]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True 允许重复  =》 相同位置\n",
    "rdd.takeSample(True, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "56d0a721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 54, 1233, 4, 8, 7, 2123, 123, 6]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeSample(False, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7d313",
   "metadata": {},
   "source": [
    "## 10. takeOrdered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "332467b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 7]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a98bd461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 1233, 123]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(3, lambda x:-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ac8ab",
   "metadata": {},
   "source": [
    "## 11. foreach => 没有返回值的map => excutor 直接输出 (eg输入数据库)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e095b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreach(lambda x:x*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b5d0d3",
   "metadata": {},
   "source": [
    "## 12.saveAsTextFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7784e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd.saveAsTextFile(\"../All/PySpark/out1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21a69d",
   "metadata": {},
   "source": [
    "## 13. mapPartition =》 一整个分区。  map 是一次处理一条.  Cpu 一样 但是空间复杂度网络io更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3ee065dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(iter):\n",
    "    result = list()\n",
    "    for it in iter:\n",
    "        result.append(it*10)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb280e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1230, 21230, 12330, 40, 540, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapPartitions(process).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83422460",
   "metadata": {},
   "source": [
    "## 14. foreachpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5df7329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.foreachPartition(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9be563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de368a33",
   "metadata": {},
   "source": [
    "## 15. partitionBy => 自定义分区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3aae97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(k):\n",
    "    if k =='hadoop'or k =='hellow': return 0\n",
    "    if k =='spark': return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff5b527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd= sc.parallelize([('hadoop', 1), ('hadoop', 1), ('spark', 1), ('flink', 1), ('hellow', 1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b8cc694e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('hadoop', 1), ('hadoop', 1), ('hellow', 1)], [('spark', 1)], [('flink', 1)]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.partitionBy(3, process).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb6371",
   "metadata": {},
   "source": [
    "## 16.repartition coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2c84a764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.repartition(1).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5d35c340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.repartition(5).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f0b309a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.coalesce(1).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6c685544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.coalesce(5, shuffle=True).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a740927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f91483bb",
   "metadata": {},
   "source": [
    "# 面试\n",
    "\n",
    "\n",
    "# 1. 功能 grouyByKey => 只分组； reduceByKey=> 分组加聚合\n",
    "\n",
    "# 2. 性能 groupbykey 性能远低于 reducebykey\n",
    "\n",
    "# reducebykey 先聚合 后 发送 后 最终聚合 => 网络io 走的少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.textFile('word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ac4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd1.flatMap( lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08663fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map( lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91458757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bd34a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5f1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c30b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.reduceByKey(lambda a,b : a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d245576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hadoop', 6), ('spark', 3), ('flink', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a326f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd3.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2115202",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd6 = rdd5.mapValues(lambda x:sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9e0c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hadoop', 6), ('spark', 3), ('flink', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd6.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1277c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d4689be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c8817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdff29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f36d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6cd79",
   "metadata": {},
   "source": [
    "# eg \n",
    "# 网站日志\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9172cd",
   "metadata": {},
   "source": [
    "## 1. 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c62d39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8b02124",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rdd = sc.textFile('SogouQ.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fde2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rdd = file_rdd.map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff1c4401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[49] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_rdd.persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1f27c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21:00:07', '05687877046704298', '传智播客', '5', '29', 'http://www.itcast.cn']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_rdd.takeSample(True, 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c35e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_jieba(data):\n",
    "    seg = jieba.cut_for_search(data)\n",
    "    l = list()\n",
    "    for word in seg:\n",
    "        l.append(word)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d22188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(data):\n",
    "    return data not in ['谷', '帮', '客']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cce38d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_words(data):\n",
    "    if data =='传智播': data ='传智播客'\n",
    "    if data  =='院校' : data ='院校帮'\n",
    "    if data  =='博学' : data ='博学谷'\n",
    "    return (data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e922b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_rdd = split_rdd.map(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18722945",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rdd = context_rdd.flatMap( context_jieba )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15d3d767",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " '博学',\n",
       " '谷',\n",
       " 'IDEA',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'flume',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " 'IDEA',\n",
       " '酷丁鱼',\n",
       " 'bigdata',\n",
       " 'itcast',\n",
       " 'flume',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'itheima',\n",
       " 'itcast',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'itheima',\n",
       " 'hadoop',\n",
       " '酷丁鱼',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'hadoop',\n",
       " 'itcast',\n",
       " '酷丁鱼',\n",
       " 'scala',\n",
       " '酷丁鱼',\n",
       " '酷丁鱼',\n",
       " '传智汇',\n",
       " 'c',\n",
       " '语言',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " 'itcast',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '传智播',\n",
       " '客',\n",
       " 'java',\n",
       " 'itheima',\n",
       " 'IT',\n",
       " '培训',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '酷丁鱼',\n",
       " '传智播',\n",
       " '客',\n",
       " 'c',\n",
       " '语言',\n",
       " 'spark',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'itheima',\n",
       " 'itheima',\n",
       " 'DataLake',\n",
       " '数据',\n",
       " '湖',\n",
       " 'c',\n",
       " '语言',\n",
       " 'itheima',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'itheima',\n",
       " 'c',\n",
       " '语言',\n",
       " 'IDEA',\n",
       " 'itheima',\n",
       " '博学',\n",
       " '谷',\n",
       " 'bigdata',\n",
       " 'DataLake',\n",
       " 'bigdata',\n",
       " 'itheima',\n",
       " '传智汇',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智播',\n",
       " '客',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " 'bigdata',\n",
       " '数据',\n",
       " '湖',\n",
       " 'kafka',\n",
       " '院校',\n",
       " '帮',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'itcast',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " 'itcast',\n",
       " '博学',\n",
       " '谷',\n",
       " '院校',\n",
       " '帮',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " '传智',\n",
       " '专修',\n",
       " '学院',\n",
       " 'bigdata',\n",
       " 'bigdata',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " '黑马',\n",
       " '程序',\n",
       " '程序员',\n",
       " '数据',\n",
       " '仓库',\n",
       " '数据仓库',\n",
       " '传智汇',\n",
       " 'hadoop',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " '博学',\n",
       " '谷',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'bigdata',\n",
       " 'kafka',\n",
       " 'itheima',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " word_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d14a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word =  word_rdd.filter(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bbabbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fianl_word_rdd = filter_word.map(append_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b571f3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scala', 2310),\n",
       " ('hadoop', 2268),\n",
       " ('博学谷', 2002),\n",
       " ('传智汇', 1918),\n",
       " ('itheima', 1680)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fianl_word_rdd.reduceByKey(lambda a,b : a+b) . sortBy(lambda x:x[1], ascending=False , numPartitions=1).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dffd7e",
   "metadata": {},
   "source": [
    "## 2.用户和关键词组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "339170b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_and_word(data):\n",
    "    ## data=> (1, 'wo ai ni')\n",
    "    user_id = data[0]\n",
    "    content = data[1]\n",
    "    \n",
    "    words = context_jieba(content)\n",
    "    return_list = list()\n",
    "    for word in words:\n",
    "        if filter_words(word):\n",
    "            \n",
    "            return_list.append((user_id + '_'+ append_words(word)[0], 1))\n",
    "    return return_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b007b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content_rdd = split_rdd.map(lambda x: (x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bea35c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2982199073774412', '传智播客')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_content_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40565159",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_word_with_one_rdd = user_content_rdd.flatMap(extract_user_and_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32599c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2982199073774412_传智播客', 1)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_word_with_one_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1d7bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6185822016522959_scala', 2016),\n",
       " ('41641664258866384_博学谷', 1372),\n",
       " ('44801909258572364_hadoop', 1260),\n",
       " ('7044693659960919_数据', 1120),\n",
       " ('7044693659960919_仓库', 1120)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_word_with_one_rdd.reduceByKey(lambda a,b : a+b) . sortBy(lambda x:x[1], ascending=False , numPartitions=1).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3d6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56568b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3959986e",
   "metadata": {},
   "source": [
    "## 3 时间段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb82c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_rdd = split_rdd.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4054bfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00:00:00']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ae9f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_with_one_rdd = time_rdd.map(lambda x:  (    x.split(':')[0] , 1   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4880eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20', 3479), ('23', 3087), ('21', 2989), ('22', 2499), ('01', 1365)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour_with_one_rdd.reduceByKey(lambda a,b : a+b) . sortBy(lambda x:x[1], ascending=False , numPartitions=1).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ac548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ded95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7b3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a0585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cebf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5506ba58",
   "metadata": {},
   "source": [
    "# 广播变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0693deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_info_list = [ (1, 'ZS', 11),\n",
    "                    (2, 'WE', 13),\n",
    "                    (3, 'rE', 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3013ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.本地广播变量\n",
    "broadcast = sc.broadcast(stu_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ce88c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_info_rdd = sc.parallelize([(1,'语文',99),\n",
    "(2,'语文',99),\n",
    "(3,'语文',99)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3bbbb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(data):\n",
    "    s_id = data[0]\n",
    "    \n",
    "    # 从广播变量取出\n",
    "    \n",
    "    for stu_info in broadcast.value:\n",
    "        stu_id = stu_info[0]\n",
    "        \n",
    "        if stu_id==s_id:\n",
    "            name = stu_info[1]\n",
    "            \n",
    "    return (name, data[1], data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80d75280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZS', '语文', 99), ('WE', '语文', 99), ('rE', '语文', 99)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_info_rdd.map(map_func).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd11647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3e211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d696d8db",
   "metadata": {},
   "source": [
    "# 累加器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8b448e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9, 10], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7ed536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acmlt = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c7201af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(data):\n",
    "    global acmlt\n",
    "    acmlt+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5add3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd.map(map_func)\n",
    "rdd2.collect()\n",
    "print(acmlt)\n",
    "rdd3 = rdd2.map(lambda x:x)\n",
    "rdd3.collect()\n",
    "print(acmlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9129fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "acmlt = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fed58de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd.map(map_func)\n",
    "\n",
    "\n",
    "\n",
    "rdd2.cache()\n",
    "\n",
    "\n",
    "rdd2.collect()\n",
    "print(acmlt)\n",
    "rdd3 = rdd2.map(lambda x:x)\n",
    "rdd3.collect()\n",
    "print(acmlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e3aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27882e9",
   "metadata": {},
   "source": [
    "# EG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "525f3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "569f245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rdd = sc.textFile('accumulator_broadcast_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "604dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = [',', '.', '!', '#', '$', '%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "52d460f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast = sc.broadcast(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4cb2e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acmlt = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab59ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 有内容就是 TRrue。 None 就是false\n",
    "lines_rdd = file_rdd.filter(lambda line: line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2135c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   hadoop spark # hadoop spark spark',\n",
       " 'mapreduce ! spark spark hive !',\n",
       " 'hive spark hadoop mapreduce spark %',\n",
       " '   spark hive sql sql spark hive , hive spark !',\n",
       " '!  hdfs hdfs mapreduce mapreduce spark hive',\n",
       " '  #']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "77a26054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = lines_rdd.map(lambda line:line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b96e0e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadoop spark # hadoop spark spark',\n",
       " 'mapreduce ! spark spark hive !',\n",
       " 'hive spark hadoop mapreduce spark %',\n",
       " 'spark hive sql sql spark hive , hive spark !',\n",
       " '!  hdfs hdfs mapreduce mapreduce spark hive',\n",
       " '#']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5bd15a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                         \\s+  =》 不确定多少空格\n",
    "words_rdd = data_rdd.flatMap(lambda line: re.split('\\s+', line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "78ae3984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hadoop',\n",
       " 'spark',\n",
       " '#',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'spark',\n",
       " 'mapreduce',\n",
       " '!',\n",
       " 'spark',\n",
       " 'spark',\n",
       " 'hive',\n",
       " '!',\n",
       " 'hive',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'mapreduce',\n",
       " 'spark',\n",
       " '%',\n",
       " 'spark',\n",
       " 'hive',\n",
       " 'sql',\n",
       " 'sql',\n",
       " 'spark',\n",
       " 'hive',\n",
       " ',',\n",
       " 'hive',\n",
       " 'spark',\n",
       " '!',\n",
       " '!',\n",
       " 'hdfs',\n",
       " 'hdfs',\n",
       " 'mapreduce',\n",
       " 'mapreduce',\n",
       " 'spark',\n",
       " 'hive',\n",
       " '#']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3c472377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(data):\n",
    "    global acmlt\n",
    "    \n",
    "    if data in char:\n",
    "        acmlt +=1 \n",
    "        return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9ccef0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_words = words_rdd.filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bbbfa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rdd = normal_words.map(lambda x:(x,1)).reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "002c8923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hadoop', 3),\n",
       " ('hive', 6),\n",
       " ('hdfs', 2),\n",
       " ('spark', 11),\n",
       " ('mapreduce', 4),\n",
       " ('sql', 2)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5099a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特殊字符 8\n"
     ]
    }
   ],
   "source": [
    "print('特殊字符', acmlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5701664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
